{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a baseline Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a simple GAN\n",
    "# The generator is similar to an autoencoder's decoder, and the discriminator is\n",
    "# a regular binary classifier (it takes an image as input and ends with a Dense\n",
    "# layer contianing a single unit and using the sigmoid activation functions). For\n",
    "# the second phase of each training iteration, we also need the full GAN model\n",
    "# contianing the generator followed by the discriminator.\n",
    "\n",
    "codings_size = 30\n",
    "\n",
    "generator = keras.models.Sequential([\n",
    "            keras.layers.Dense(100, activation='selu', input_shape=[codings_size]),\n",
    "            keras.layers.Dense(150, activation='selu'),\n",
    "            keras.layers.Dense(28*28, activation='sigmoid'),\n",
    "            keras.layers.Reshape([28,28])\n",
    "])\n",
    "\n",
    "discriminator = keras.models.Sequential([\n",
    "                keras.layers.Flatten(input_shape=[28,28]),\n",
    "                keras.layers.Dense(150, activation='selu'),\n",
    "                keras.layers.Dense(100, activation='selu'),\n",
    "                keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "gan = keras.models.Sequential([generator, discriminator])\n",
    "\n",
    "# Next, we need to compile these models. As the discrimiantor is a binary classifier\n",
    "# we can naturally use binary-crossentropy loss. The generator will only\n",
    "# be trained through the gan model, so we do not need to compile it at all.\n",
    "# the gan model is also binary classifier, so it can use the binary-cross entropy\n",
    "# loss. Importantly, the discriminator should not be trained during the second phase,\n",
    "# so we make it non-trianable before compiling the gan model.\n",
    "\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "discriminator.trainable = False\n",
    "gan.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "# The trainable attribute is taken into account by Keras only when compiling a model,\n",
    "# so after running this code, the discriminator is trainable if we call the fit(0 method\n",
    "# or its train_on_batch() method (which we will be using), while it is not trainable\n",
    "# when we call these methods on the gan model)\n",
    "\n",
    "# Since the trianing loop is unusual, we cannot use the regular fit() method. Instead\n",
    "# we will write a custom training loop. For this, we first need to create a Dataset\n",
    "# to iterate through the images.\n",
    "\n",
    "batch_size=32\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X_train).shufflt(1000)\n",
    "dataset= dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n",
    "\n",
    "# We are now ready to write the training loop. Let's wrap it in a train_gan(0) function.\n",
    "\n",
    "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n",
    "    generator, discriminator = gan.layers\n",
    "    for epoch in range(n_epohcs):\n",
    "      for x_batch in dataset:\n",
    "        #phase 1 training the discriminator\n",
    "        noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "        generated_images = generator(noise)\n",
    "        X_fake_and_real = tf.concat([generated_images, x_batch], axis=0)\n",
    "        y1 = tf.constant([[0.]]*batch_size + [[1.]] * batch_size)\n",
    "        discriminator.trainable = True\n",
    "        discriminator>train_on_batch(x_fake_and_real, y1)\n",
    "        # phase 2, training on the generator\n",
    "        y2 = tf.constant([[1.]]*batch_size)\n",
    "        discriminator.trainable = False\n",
    "        gan.train_on_batch(noise, y2)\n",
    "\n",
    "train_gan(gan, dataset, batch_size, codings_size)\n",
    "\n",
    "# A GAN can only reach a single nash equilibrium, where changing strategies offers\n",
    "# no benefits: when the generator produces perfectly realistic images and the \n",
    "# discriminator is forced to gues 50/50. No guarantee this equilibrium will\n",
    "# ever be reached. Mode collapse, when generator's outputs are less diverse.\n",
    "# picks one thing it tricked the discrim on, and forgets everything else.\n",
    "# experience replay to drop old images, so it forgets what its good at, and instead\n",
    "# focuses on being good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Deep Convolutional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Convolutional GANs\n",
    "# For larger images. Replace any pooling layers with strided convs (in the discr)\n",
    "# and transposed convolutions (in the generator).\n",
    "# Use Batch Normalization in both the generator and discriminator, except in \n",
    "# the generator's output layer and the discriminator's input layer.\n",
    "# Remove fully connected hidden layers for deeper architectures.\n",
    "# Use RELU activation in the generator for all layers except the output layer,\n",
    "# which should use tanh.\n",
    "# Use Leaky Relu activation in the discriminator for all layers.\n",
    "\n",
    "codings_size = 100\n",
    "\n",
    "generator = keras.models.Sequential([\n",
    "            keras.layers.Dense(7*7*128, input_shape=[codings_size]),\n",
    "            keras.layers.Reshape([7, 7, 128]),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding='same',\n",
    "                                         activation='selu')\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2, padding='same',\n",
    "                                         activation='tanh')\n",
    "])\n",
    "\n",
    "discriminator = keras.models.Sequential([\n",
    "                keras.layers.Conv2D(64, kernel_size=5, strides=2, padding='same',\n",
    "                                    activation=keras.layers.LeakyReLU(0.2),\n",
    "                                    input_shape=[28,28,1]),\n",
    "                keras.layers.Dropout(0.4),\n",
    "                keras.layers.Conv2D(129, kernel_size=5, strides=2, padding='same',\n",
    "                                    activation=keras.layers.LeakReLU(0.2)),\n",
    "                keras.layers.Dropout(0.4),\n",
    "                keras.layers.Flatten(),\n",
    "                keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "gan = keras.models.Sequential([generator, discriminator])\n",
    "\n",
    "# The generator takes codings of size 100, and it projects them to 6272 dimensions\n",
    "# 7*7*128, and reshapes the reslt to get a 7x7x128 tensor. This tensor is batch norm\n",
    "# and fed to a transposed conv layer with a stride of 2, which upsamples it from 7x7 to\n",
    "# 14x14 and reduces the depth from 128 to 64. The result is batch normed again and fed to\n",
    "# another transposed conv layer with a stride of 2, which upsamples it from 14x14 to 28x28\n",
    "# and reduces the depth from 64 to 1. This layer uses the tanh activation function, so the \n",
    "# outputs will range from -1 to 1. For this reason, before training the GAN, we need to \n",
    "# rescale the training set to that same range. We also need to rehspae it to add the \n",
    "# channel dimension.\n",
    "\n",
    "X_train = X_train.reshape(-1,28,28,1) *2. - 1. #reshape and rescale\n",
    "\n",
    "# The discriminator looks much like a regular CNN for binary class, except of a\n",
    "# max pool layer to downsample the image, we use strided convs. Lastly to build\n",
    "# the dataset, then compile and train this model, we use the exact same code as \n",
    "# earlier. After 50 epochs, the generator produces images.\n",
    "\n",
    "# If you add each image's class as a extra input to both the generator\n",
    "# and the discriminator, they will both learn what each class looks like,\n",
    "# and thus you will be able to control the class of each image produced\n",
    "# by the generator. This is called a Conditional GAN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
